Всего: 7 минут, 14 слайдов => ~ 30 секунд на слайд

Слайд 1

Всем добрый день! Сегодня я расскажу по свою дипломную работу под названием
"Методы оценки сложности текстовых данных для ускорения обучения языковых моделей с помощью обучения по плану"

Слайд 2

Сейчас основными моделями для решения большинства важных задач в NLP являются трансформеры. Я же в своей работе использую модель BERT, т.к. она является наиболее популярной, имеет высокое качество
и сравнительно небольшой размер для удобства постановки экспериментов

Слайд 3

Чтобы BERT применить, его нужно обучить. Обучение состоит из двух
этапов. Первый этап -- предобучение. Здесь BERT обучают восстанавливать предложение после замены 15% случайных слов на
пробелы. Это делают на огромных датасетах, например на Wikipedia. Предобучение занимает несколько недель при
использовании дорогостоящих высокопроизводительных видепроцессоров. Второй этап -- дообучение. Здесь модель
учат решать конкретную задачу. На данном этапе требуется меньше ресурсов, однако это все еще занимает много времени.
Важно отметить, что в обоих этапах нужно работать большими объемами данных в несколько десятков миллинов примеров
текстов длины порядка 200-500.

Слайд 4

Для того, чтобы справиться с проблемой большого потребления ресурсов, люди используют разные методы. Но объектом моего
изучения является именно обучение по плану (curriculum learning в англоязычной литературе). Напомню определение: обучение
по плану состоит из двух частей: сортировки данных по сложности и алгоритма семплирования данных. Например, можно отсортировать
тексты по длине и семплировать из растущего префикса

Слайд 5

В своей работе я изучаю влияние метрик на скорость обучения моделей, поэтому важно понять, как сранивать две метрки между собой.
Давайте зафиксируем все кроме двух метрик. Обучим две независимые модели. Зафиксируем достаточно большой порог качества 
(например. 95% итогового качества) и посчитаем среднее число шагов, которое нужно для его достижения при применении обеих 
метрик. Будем говорить, что одна метрика быстрее другой, если она требует меньшего числа шагов.

Слайд 6

На данный момент, обучение по плану активно изучается, но именно в NLP есть ограниченное число работ. Так, уже были
использованы такие метрики, как длина и правдоподобие, частота слов и модельная метрика. Важно отметить, что
авторы применяли подходы на задаче машинного перевода, в то время как задачи классификации и предобучения совсем
не исследованы. В существующих работах малое внимание уделяется метрикам. Так, наиболее очевидна метрика длина
является лидирующей. Более того, авторы в основном стараются ускорить качество модели, а не скорость обучения.
Так Xu с коллегами улучшиили качество модели, увеличив время обучения в несколько раз. Также, даже в смежных
областях машинного обучения существуют как положительные, так и отрицательные результаты. Так, Ву показал, что на задаче 
классификации картинок обучения по плану не улучшает ни качество итоговой модели, ни скорость ее обучения.
Таким образом, есть широкое поле для исследаний и мы готовы сформулировать цель и задачи данной работы.

Слайд 7

Целью данной работы является ускорение обучения языковой модели BERT ... (прочитать)
Ее я разбил на подзадачи, а именно нужно ...

Слайд 8

Начнем с метрик. Я рассмотрел базовые метрики, взятые из существующих работ, а именно длину, вероятность правдоподобия и ранг
самого редкого слова в предложении. Далее я посмотрел на эту задачу с двух сторон. С точки зрения информационного поиска, т.к. данная
область пытается выделить в документах самое важное, для их быстрого поиска по запросу. Из нее я взял одну из самых популярных
метрик: TF-IDF. Чтобы рассмотреть задачу с точки зрения теории информации, я обратился к работе Нихата, где он и его коллеги предложили
униврсальный подход к оценке сложности конечных дискретных систем. Из данной работы я взял 2/4 предложенных метрик, т.к. только 
их получилось адаптировать под тексты. А адаптировал я их следующим образом. Метрики требуют на вход некоторую случайную величину.
Я ее строю напрямую из текста. Каждое слово t_i в тексте T я строю свою бинарную с.в., которая зависит от позиции слова в тексте и ее 
значения. Теперь мы можем использовать метрики теории информации, не потеряли структуру предложение и учитывает статистические 
особенного данного примера по отношению ко всему датасету. Этим все не закончилось. Подсчет метрик EE и TSE по определнию
занимал большое количество времени, поэтому я придумал алгоритм для их вычисления за линиейное время, что привело к
значительному ускорению. Также. я использую MLMloss как аналог модельным метрикам сущесвтующих работ.
Про метрику TPW я расскажу чуть позже

Слайд 9

Более того, для вычисления всех метрик нужно собрать статискти, представленные на слайде со всего набора данных. Наивное решение
также требовало много врмение, поэтому я предложил делать это параллельно, благо это можно сделать, просто разделив датасет
на несколько частей и посчитать на каждой из них независимо.
В итоге, был предложен ряд метрик, расширяющий множество уже существующих, некоторые были адаптированы под работу с текстами,
а также были предлоежны алгоритмы для их быстрого вычисления. Теперь перейдем к экспериментальной части работы.

Слайд 10

Начнем с задачи предобучения. Для экспериментов был использован датасет BooksCorpus из множества отрывков из книг.
В ходе исследования было выяснено, что все метрики вне зависимости от семплера имеют строгий поряодок, указанный на слайде.
Также виден сильный проигрыш обучения по плану по сравнению с обучением без плана. Чтобы определить это точнее, обратимся
к сравнительной таблице.

Слайд 11

Метрики разделены на две группы. Это связано с тем, что в первой группе метри-
ки сходятся к гораздо более низким значениям по сравнению с метрками из второй
группы. Следовательно тяжело выбрать такой порог, на котором можно было бы раз-
личать метрики внутри каждой группы. Заметим, что в первой группе
максимальный ранг слова позволяет получить такое же качество итоговой модели,
как у базового подхода. В то время как остальные подходы такой возможности не
предоставляют. применение
обучения по плану приводит к замедлению от 2 до 5 раз.

Слайд 12

Теперь перейдем к задаче классификации. Здесь я использовал датасеты sentiment140 и Hyperpartisan News Detection. Первый состоит из полутора миллинов твиттов, а второй из политических текстов. Я опшиу результаты только на первом датасете.

заметим, что при использовании обучения по
плану проседает итоговая точность модели на 0.3% для всех метрик кроме длины и
MLM_loss, где точность проседает почти на процент

Если выбрать высокий порог точности в
85.5% (-1.5% итоговой точности), то разница в метриках существенна, а именно мет-
рики TF-IDF, TSE и максимальный ранг слова приводят к хоть и не значительному,
24но ускорению обучения на 3%. Остальные метрики замедляют скорость сходимости
модели.

Длина же ни в одной конфигу-
рации не позволяет ускорить обучение модели, что подтверждает гипотезу о том, что
данная метрика не является разумным выбором метода оценки сложности текстов в
контексте обучения по плану.

Слайд 13

Истинную причину проигрыша обучения по плану установить не удалось. Однако, получилось найти его применении при обучении на шумном корпусе данных. Для этого я искусственно добавил в датасет шум. Я рассмотрел три вида шума наиболее приближенных к реальности. Также заметим, что уровень шума мы можем сами регулировать и что это также можно рассмореть как метрику сложности. Эксперименты с этой метрикой показали, что в начале модель учится в 2.5 раза быстрее. Однако в реальной жизни мы не знаем, какой уровень шума у примера, но я заметил, что среднее число токенов на слово больше у шумных примеров чем у чистых, поэтому после сортировки по этой метрике в начале датасете находятся чистые примеры, а в ближе к концу модель плавно переходить к более шумным. Это привело к тому, что модель достигает 95% точности итоговой модели примерно в два раза быстрее 

Слайд 14

В итоге были предложен ряд метрик и производительные алгоритмы к ним, проведены эксприменты на задачах
предобучения и классификации. На предобучении не получилось ускорить обучение. На классификации получилось
несущественно ускорить на 3%. На шумных данных получилось ускорить в два раза.