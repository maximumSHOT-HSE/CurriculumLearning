% В этом шаблоне используется класс spbau-diploma. Его можно найти и, если требуется, 
% поправить в файле spbau-diploma.cls
\documentclass{spbau-diploma}
\usepackage{graphicx}
\begin{document}
% Год, город, название университета и факультета предопределены,
% но можно и поменять.
% Если англоязычная титульная страница не нужна, то ее можно просто удалить.
\filltitle{ru}{
    chair              = {\ },
    title              = {\textbf{ВЫПУСКНАЯ КВАЛИФИКАЦИОННАЯ РАБОТА\\(БАКАЛАВРСКАЯ РАБОТА)}\vskip 0.5 em на тему \vskip 0.5 em\textbf{«Методы оценки сложности текстовых данных для ускорения обучения языковых моделей с помощью обучения по плану»}\\\textit{\small Направление подготовки 01.03.02 Прикладная математика и информатика}},
    % Здесь указывается тип работы. Возможные значения:
    %   coursework - Курсовая работа
    %   diploma - Диплом специалиста
    %   master - Диплом магистра
    %   bachelor - Диплом бакалавра
    % type               = {diploma},
    position           = {студента},
    group              = {БПМ171С},
    author             = {Сурков Максим Константинович},
    supervisorPosition = {?},
    supervisor         = {Ямщиков Иван Павлович},
    reviewerPosition   = {ст. преп.},
    reviewer           = {Привалов А.\,И.},
    % chairHeadPosition  = {д.\,ф.-м.\,н., профессор},
    % chairHead          = {Омельченко А.\,В.},
    university = {\textbf{Федеральное государственное автономное образовательное учреждение высшего образования\\«Национальный исследовательский университет\\«Высшая школа экономики»}},
    faculty = {Факультет Санкт-Петербургская школа физико-математических и компьютерных наук\\Департамент информатики},
    city = {Санкт-Петербург},
    year = {2021}
}
\maketitle

\tableofcontents
\section*{Аннотация}
\ 

Современные системы обработки естественного языка активно используют глубокие нейронные сети (BERT, GPT-3), которые требуют значительных ресурсов для их обучения. За последние годы было разработано множество подходов для решения данной проблемы. Одним из них является обучение по плану. Данный метод состоит из двух составляющих: оценки сложности тренировочных данных и алгоритма их семплирования. Основной целью данной работы является исследование метрик оценки сложности текстовых данных в контексте обучения по плану и влияния данного метода ускорения обучения на скорость сходимости языковых моделей на задачах предобучения и классификации. В процессе исследований было предложено и адаптировано несколько подходов из разных областей математики. Также были реализованы производительные алгоритмы вычисления найденных метрик на больших объемах данных в несколько десятков миллинов тренировочных примеров. Объемный набор экспериментов на задачах предобучения и классификации  выявил наиболее эффективные метрики для использования в обучении по плану. В то же время было установлено, что обучение по плану негативно влияет на скорость сходимости на задаче предобучения, однако не уступает базовому подходу (обучению без плана) на задаче классификации. Также был рассмотрен важный частный случай обучения языковой модели на шумном наборе тренировочных данных. Сравнительный анализ показал ускорение обучения до двух раз на первых 10\% обучения при применении обучения по плану с наиболее эффективной метрикой.
\\

Ключевые слова: обработка естественного языка, обучение по плану, теория информации, оценка сложности текстовых данных

\pagebreak

Modern state-of-the-art natural language processing systems use deep neural networks (BERT, GPT-3) that require many resources for training. Several techniques have been developed for the last ten years. One of them is curriculum learning, which consists of two parts, namely data complexity evaluation and sampling. The main purpose of this work is to research metrics of text complexity in the context of curriculum learning and explore the influence of curriculum learning on training time on pre-training and classification tasks. Several approaches from different mathematics fields were suggested and adapted during the research. Moreover, efficient algorithms for calculating given metrics on large datasets of several tens of millions of samples were implemented. Extensive experiments highlighted the most efficient metrics for use in curriculum learning. At the same time, it was established that curriculum learning negatively affects convergence time on pre-training task, but not inferior to the basic solution (learning without curriculum) on the classification task. Also, training on a noisy training dataset was considered. Comparative analysis showed a double reduction in training time on the first 10\% of training using curriculum learning with the most effective metric.

Keywords: natural language processing, curriculum learning, information theory, text complexity estimation
\section*{Введение}
\ 

На сегодняшний день существует множество сфер, где активно применяется обработка естественного языка. Например, в разработке голосовых помощников, алгоритмов фильтрации текста и машинного перевода. Возникающие задачи необходимо решать эффективно с точки зрения качества модели и скорости работы системы. За основу многих подходов взят механизм внимания~\cite{vaswani2017attention}. На его базе были разработаны модели, такие как BERT~\cite{devlin2018bert}, GPT-3~\cite{brown2020language} и многие другие. Данные сети имеют высокое качество, однако, за это приходится платить существенным временем обучения. В рамках данной работы исследуется влияние обучения по плану на примере тренировки модели BERT, так как она является одной из самых популярных моделей, имеет высокую точность и сравнительно небольшой размер для удобства постановки экспериментов. Также стоит отметить, что для обучения модели используют объемные корпуса данных, состоящие из нескольких десятков миллионов примеров, для которых нужны производительные алгоритмы их обработки. 

\begin{table}[h]
	\label{table:dataset_sizes}
	\caption{Количество примеров в тренировочных корпусах данных}
	\centering
	\begin{tabular}{|l|c|}
		\hline
		Корпус данных & Размер \\
		\hline\hline
		Wikipedia & 3-600M \\
		BookCorpus & 74M\\
		\hline\hline
		Hyperpartisan News Detection & 600k-2M \\
		sentiment140 & 1.6M \\
		IWSLT & 200-230k \\
		QQP & 364k \\
		MNLI & 393k \\
		\hline
	\end{tabular}
\end{table}

Процесс тренировки модели состоит из двух основных частей. Первая заключается в предобучении сети на задаче Masked Language Modelling~\cite{devlin2018bert}, которая состоит в восстановлении предложения после замены 15\% случайных слов на пробелы. Предобучение занимает несколько недель исполнения кода на дорогостоящих графических процессорах. Второй этап представляет из себя задачу дообучения языковой модели, например на задачу классификации, и требует несколько дней даже на элементарных задачах, таких как определение спама или грубой речи~\cite{gertner2019mitre}. Одним из методов ускорения обучения моделей является обучение по плану~\cite{bengio2009curriculum}. При его применении данные сортируются по сложности, а затем семплируются с помощью заранее определенного алгоритма, который учитывает порядок данных. Данный подход хорошо себя показал во многих областях машинного обучения~\cite{narvekar2020curriculum, hacohen2019power, mermer2017scalable}, однако в обработке естественного языка существует лишь ограниченное число успешных работ~\cite{platanios2019competence, xu2020curriculum}. Более того, на данный момент нет исследований влияния обучения по плану на скорость сходимости модели на задачах предобучения и классификации. Также в существующих работах авторы уделяют большое внимание алгоритмам семплирования данных, а метрики берут из достаточного узкого множества, которое можно значительно расширить, применив различные сферы компьютерных наук. Это позволяет обозначить широкое поле для исследований подходов к оценке сложности текстов и предположить, что существует метрика, которая позволит значительно ускорить обучение модели на вышеуказанных задачах. Однако, в последнее время стали появляться работы с отрицательными результатами применения обучения по плану на задачах компьютерного зрения~\cite{wu2020curricula}, что показывает спорную репутацию данного подхода к ускорению. В то же время, в тех же статьях авторы находят частные случаи применения обучения по плану на практике. Таким образом, можно выделить обширную сферу исследований нетривиального вопроса применимости обучения по плану к ускорению тренировочного процесса языковых моделей на задачах предобучения и классификации.

\subsection*{Цель и задачи}
\ 

Целью данной работы является ускорение обучения языковой модели BERT c помощью обучения по плану за счет применения улучшенной метрики сложности текстовых данных на задачах классификации и предобучения
\begin{itemize}
	\item Предложить метрики оценки сложности текста
	\item Реализовать производительные алгоритмы вычисления предложенных метрик на больших корпусах данных
	\item Сравнить найденные метрики
	\item Исследовать влияние найденных метрик на скорость обучения языковой модели BERT на чистых и шумных тренировочных данных
\end{itemize}
\subsection*{Достигнутые результаты}
\subsection*{Структура работы}
\section{Обзор литературы}
\subsection{Возникновение обучения по плану}
\ 

Точная дата возникновения обучения по плану не известна, но можно выделить логическое начало в работе Bengio 2009 года~\cite{bengio2009curriculum}, в которой было показано, что обучение по плану может привести к улучшению качества моделей машинного обучения. Авторы поставили несколько экспериментов, одним из которых является опыт по обучению классификатора геометрических фигур. Было обнаружено, что если сначала предъявить модели более простые примеры (квадраты, круги, равнобедренные треугольники) перед стандартным алгоритмом обучения, то итоговое качество возрастет. Этот простой пример подчеркивает большой потенциал обучения по плану к улучшению существующих алгоритмов в машинном обучении.
\subsection{Применение обучения по плану в смежных сферах машинного обучения}
\ 

Обучение по плану активно применялось в разных областях машинного обучения в течение последних нескольких лет. Например, Hacohen и Weinshall в 2019 году~\cite{hacohen2019power} применили данный метод к задачам компьютерного зрения. Они предложили модельную метрику оценки сложности картинок, которая считается следующим образом. Рассматривается независимая модель, предобученная на датасете ImageNet. Далее сложность примера определяется как уверенность модели в своем предсказании. Наконец, ученые использовали лестничный алгоритм семплирования в паре с предложенной метрикой. В результате был получен прирост в скорости обучения и в качестве итоговой модели.

Обуение по плану применяется в и классическом глубоком обучении. Mermer и др.~\cite{mermer2017scalable} предложили способ автоматической оценки сложности векторных данных для решения задачи классификации. Для этого авторы для каждого примера строят распределение вероятностей классов двумя способами.
\begin{enumerate}
	\item на базе $k$ ближайших соседей. Рассмотрим мультимножество меток соседей, тогда вероятность $i$-го класса равна доле соседей с данной меткой
	\item на базе ансамбля. Обучим $k$ независимых классификаторов стандартным алгоритмом. Далее для каждой метки определим среднюю предсказанную классификаторами вероятность того, что данный пример имеет рассматриваемую метку
\end{enumerate}
	
В итоге сложность примера вычисляется как энтропия построенного распределения. Авторы рассмотрели $36$ датасетов, на многих из которых обучение по плану выиграло у стандартного алгоритма обучения. Заметим, что подход, основанный на метках соседей, невозможно применить к текстам в явном виде, так как примеры из естественного языка не имеют векторной структуры. Однако можно рассмотреть пространство эмбеддингов. Но данный способ будет зависеть от метода получения векторного представления текстов. Более того, размеры датасетов обучения языковых моделей состоят из большого числа примеров, и поиск $k$ ближайших соседей может требовать большого количества времени, что недопустимо при решении задачи ускорения обучения. Те же самые проблемы возникают и при применения подхода, основанного на ансамблировании.

Важно отметить, что при применении обучения по плану можно получить и отрицательный результат. Так Wu и др.~\cite{wu2020curricula} выявили негативное влияние обучения по плану на скорость обучения широкого множества глубоких нейронный сетей на задаче классификации картинок. Авторы применили данный подход к более чем сотне архитектур, среди которых ResNet и VGG-19. Авторы рассмотрели несколько метрик сложности данных, которые сильно коррелировали с величиной $s(x_i, y_i)$ последней эпохи $t$	, после которой модель $w$ правильно отвечает на пример $(x_i, y_i)$ вплоть до последней эпохи $T$ (предсказание модели $\hat{y}_w(t)$ совпадает с реальной меткой $y_i$ примера), для которого считается сложность (формула~(\ref{eq:learned_epoch})). 

\begin{equation} \label{eq:learned_epoch}
s(x_i, y_i) = \min_{t^*}\{\hat{y}_w(t)_i = y_i,\forall t^* \le t \le T\}
\end{equation}

Было использовано семейство "префиксных" семплеров (рис.~\ref{fig:cv_pacing_functions}), а именно возрастающих функций, которые определяют долю легких примеров $g(t)$ в конкретный момент обучения $t$. Таким образом, данные семлперы в момент времени $t$ строят батч данных, равноверятно выбираея примеры из первых $g(t)$ семплов отсортированного по метрике сложности датасета. В результате, ученые показали, что при использовании данной конфигурации обучения по плану не приводит ни к улучшению качества итоговой модели, ни к ускорению обучения. Также было рассмотрено два важных частных случая, а именно обучение на шумных данных и обучение с ограниченным числом тренировочных шагов. При добавлении 20\% шума в тренировочный корпус, обучение по плану позволяет улучшить точность модели на 10\%. Влияние же подхода на скорость обучения исследовано не было.

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.48]{CV_pacing_functions}
	\caption{Семейство функций для семплирования данных}
	\label{fig:cv_pacing_functions}
\end{figure}

\subsection{Применение обучения по плану в обработке естественного языка}
\ 

В обработке естественного языка существует ограниченное число существенных результатов в контексте применения обучения по плану. Вероятно, это связано с тем, что естественный язык состоит из слов и предложений, не имеющих строгую структуру, которую сложно формально описать. Более того, на данный момент наука не понимает всех процессов, происходящих внутри современных языковых моделей.

Platanios и др.~\cite{platanios2019competence} исследовали влияние обучения по плану на задаче машинного перевода на скосрость сходимости нейронных сетей. Авторы рассмотрели две метрики сложности текстов: длину и вероятность правдоподобия, которая вычисляется по формуле (\ref{eq:log_likelihood}), где $s_i$ -- текст или набор токенов, $w_k^i$ -- слово или токен, $p(x)$ -- доля токенов $x$ во всем датасете.

\begin{equation} \label{eq:log_likelihood}
d(s_i) = -\sum\limits_{k=1}^{N}\log p(w_k^i)
\end{equation}

Они показали, что правдоподобие не имеет никаких преимуществ по сравнению  с длиной с точки зрения скорости обучения моделей. В качестве семплеров был взят префиксный семплер с функцией $c(t)$ (формула (\ref{eq:competence_based_sampler})), вычисляющий долю простых примеров, доступных для построения батча.

\begin{equation} \label{eq:competence_based_sampler}
c(t) = \min\left(1, \sqrt{t\frac{1 - c_0^2}{T} + c_0^2}\right)
\end{equation}

$T$ -- общее число тренировочных шагов, $c_0$ -- доля простых примеров, доступных в самом начале обучения (авторы используют $c_0 = 0.01$)

В итоге, ученые добились улучшения качества модели на 2.2 BLEU и ускорения обучения на 70\%.

Xu и др.~\cite{xu2020curriculum} предложили альтернативный способ применения обучения по плану в обработке естественного языка на задаче Natural Language Understanding. Их метод оперирует понятием модельной оценки сложности текстов. Сложность примеров меняется в процессе обучения в зависимости от качества модели на момент применения метрики к примеру. Авторы предлагают алгоритм, который в цикле повторяет следующую процедуру. Тренировочный корпус данных разделяется на несколько частей. Затем, для каждого блока независимо обучается новая модель, которая инициализируется весами текущей глобальной модели. После этого оценивается сложность всех примеров как сумма уверенностей всех моделей по всем блокам кроме блока, в котором находится данный пример (рис. \ref{fig:acl20_algo_difficulty}).

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.48]{acl20_algo_difficulty}
	\caption{Алгоритм вычисления модельной метрики сложности текста. На данной схеме датасет делится на $4$ части, на каждой из которых учится независимая модель BERT с началными весами текущей глобальной модели. Сложность примеров в блоке под номером $3$ вычисляется как сумма уверенностей моделей $W_1,W_2,W_4$.}
	\label{fig:acl20_algo_difficulty}
\end{figure}

Наконец, весь датасет сортируется в соответствии с найденными сложностями примеров, и текущая глобальная модель обучается на новой эпохе, обрабатывая примеры в порядке возрастания сложности. Данный подход позволяет улучшить точность итогвоой модели на 1.5\%, но требует существенно больше времени.

В 2017 году Kocmi и др.~\cite{kocmi2017curriculum} провели сравнтиельный анализ двух подходов к ускорению обучения: minibatch bucketing и обучение по плану. Первый подход отличается от стандартного алгоритма обучения нейронных сетей только построением батчей, каждый из которых содержит данные, слабо отличающиеся по заранее определенному показателю (например, батч из предложений с не более чем пятью глаголами). Для обучения по плану авторы используют три метрики.
\begin{enumerate}
	\item длина предложения
	\item максимальный частотный ранг слова -- для каждого слова вычисляется количество его вхождений в тренировочный корпус данных. Затем все слова сортируются в порядке убываения частоты. Рангом слова называется его позиция в данном отсортированном массиве. Сложность предложения определяется как максимальный ранг по всем словами в данном предложении
	\item количество конъюнкций (например, эту метрику можно определить как количество союзов)
\end{enumerate}

Исследование показало, что обучение по плану позволяет увеличить качество итоговой модели на 1 BLEU, но без уменьшения времени обучения. Более того, модель, обучаемая с помощью обучения по плану достигает 85\%-го качества модели, обученной базовым алгоритмом, в два раза медленнее.

Важный вклад в исследование обучения по плану внесли Zhang и др.~\cite{zhang2018empirical} в 2018 году. В качестве метрик оценки сложности текста авторы рассматривают модельную метрику, длину, максимальный частотный ранг и средний частотный ранг. В данной работе ранг слова определяется аналогично работе Kocmi и др.~\cite{kocmi2017curriculum}. Модельная метрика определяется ошибкой вспомогательной модели, заранее обученной на задачу машинного перевода стандартным алгоритмом. Принципиальным отличием данной работы является выбор методов построения батчей. Ученые не рассматривают префиксные семплеры, а используют алгоритмы, с течением времени изменяющие распределение вероятности взять пример в текущий батч. Авторы показали, что обучение по плану очень чувствительно к выбору гиперпараметров. Среди нескольких десятков конфигураций лишь некоторые позволяют получить ускорение обучения модели до 30\% без потери точности. Также было установлено, что длина не является удачной метрикой для обучения по плану, а именно она приводит к замедлению обучения модели до двух раз и уменьшению точности модели до 4.2 BLEU.

\subsection{Существующие метрики оценки сложности текстов}
\ 

Таким образом, был рассмотрен ряд метрик, активно используемых в обучении по плану: длина~\cite{platanios2019competence, kocmi2017curriculum, zhang2018empirical}, вероятность правдоподобия~\cite{platanios2019competence}, модельная~\cite{xu2020curriculum}, максимальный~\cite{kocmi2017curriculum, zhang2018empirical} и средний~\cite{zhang2018empirical} частотный ранг.

На первый взгляд кажется, что можно придумать еще несчетное количество подходов. Действительно, существует большое количество метрик оценки сложности текстов. Это показал Kurdi в своей статье 2020 года \cite{kurdi2020text}, в которой решал задачу определения уровня английского языка, необходимого для прочтения текста. Для этого он строил множество признаков входного текста для их передачи на вход классификатору. Ученый рассмотрел несколько десятков методов определения сложности текста понятных для человека: фонологические, морфологические, лексические, синтаксические признаки и многие другие. Это позволило решить задачу с высокой точностью. Несмотря на хорошее качество полученной модели, вопрос применимости данных метрик к обучению по плану остается открытым. Однако на него можно найти ответ в работе Frans van der Sluis и Egon L. van den Broek \cite{van2010using}. Они рассмотрели два набора данных, Wikipedia и Simple English Wikipedia (упрощенная версия Wikipedia, состоит из статей меньшей длины, написанных более простым языком), и показали что лингвистические метрики плохо коррелируют с реальной сложной текстов. Таким образом, классические методы оценки сложности текстовых данных имеют меньший приоритет для рассмотрения в сранении с метриками, основанными на статистических подходах.

Оценка сложности текстов тесно связана с количеством информации в них. Этот объкт изучает теория информации. В 2006 году Ay и др. \cite{ay2006unifying} предложили четыре метода оценки сложности конечных дискретных систем. К сожалению, в чистом виде данные подходы невозможно применить к текстам, так как они (подходы) получают на вход некоторую совместно распределенную случайную величину. Однако эти метрики можно  адаптировать, о чем будет рассказано в последующих главах.

\subsection{Выводы}

\begin{itemize}
	\item Нет существующих исследований влияния обучения по плану на скорость сходимости на не менее важных задачах предобучения языквоых моделей и классификаии текстов
	\item Рассмотрено узкое множество метрик оценки сложности текстов, которое можно расширить, используя методы из смежных областей математики и информатики, таких как теория информации и информационный поиск
	\item Большинство работ применяют обучение по плану для улучшения качества модели, но не скорости ее обучения
	\item Можно заметить, что во многих работах обучение по плану приводит к уменьшению тренировочного времени и увеличению точности моделей только в определенных конфигурациях, которые сильно зависят от гиперпараметров, задачи, модели и корпуса данных. Важной деталью является тот факт, что все эксперименты были проведены на чистых наборах данных. Такая ситуация редко встречается при решении прикладных задач и реализации реальных проектов. Например, крупные компании тратят большие деньги для очистки тренировочных данных. Таким образом, важность исследования обучения языковых моделей на шумных корпусах данных очевидна, однако работ, освещяющих данный вопрос найдено не было
\end{itemize}

\section{Глава1}
\section{Глава2}
\section{Глава3}
\section{Глава4}
\section{Заключение}

% размещенный с предпочтением "вверху страницы"
% \begin{figure}[t]
% \centering
% \includegraphics{fig1.jpg}
% \caption{Разрыв функции}
% \label{разрыв_функции}
% \end{figure}

% \begin{figure}[h]
    % \includegraphics{thesis-search-trends}
    % \caption{Статистика поисковых запросов в течении года}
% \end{figur

\bibliographystyle{ugost2008ls}
\bibliography{diploma.bib}
\end{document}
