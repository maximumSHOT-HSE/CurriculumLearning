
https://arxiv.org/abs/1904.03626 - опять то же самое, только на картинках (да, опять)

https://www.aclweb.org/anthology/2020.acl-main.542.pdf - новая статья китайцев на ACL 2020, угадайте, что они делают.... они опять учат много бертов!!!!


https://www.researchgate.net/publication/221344862_Curriculum_learning - говорят, что это самая первая стать про curriculum learning в машинном обучении


Вопросы, которые можно поисследовать:
    * Как размер X влияет на ускорение за счет CL, где
        X in {модели, датасета, алфавита токенизатора}
    * Что по другим моделям? (GPT-3, разные вариации берта)

Идея для метрики:
    По сути EE - это сумма взаимных информаций в соседних токенах.
    Обобщение: сумма информаций в контекстах размера k. 
    Кажется, должно считаться за O(kn)
