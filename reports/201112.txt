[15:39]

Ище статьи про curriculum learning для nlp

[ ] https://arxiv.org/pdf/1611.06204.pdf
[+] https://www.aclweb.org/anthology/P16-1043.pdf
[~] https://arxiv.org/abs/1605.03852
[ ] https://arxiv.org/abs/1703.03091
[ ] http://www.cs.cmu.edu/~lujiang/camera_ready_papers/AAAI_SPCL_2015.pdf
[+] https://www.aclweb.org/anthology/N19-1119.pdf
[+] https://www.aclweb.org/anthology/2020.acl-main.542.pdf

[17:34] Обзор статьи https://www.aclweb.org/anthology/P16-1043.pdf ()
    * Решают задачу QA, говорят, что CL (curriculum learning) и SPL (self paced learning) улучшают скорость обучения и итоговое качество
    * Общая идея - давайте учить модель так:
        Берем первый батч, учим, дальше берем следующий батч так, чтобы минимизировать не просто итоговоый лосс,
        а обновленный лосс (который меняется во время обучения), в этом лоссе мы будем учитывать, насколько следующий батч
        подходоит под обучение (приводят несколько эвристик)

        Т.е. хотим минимизировать какой-то меняющийся лосс, а не разбивать ихсодный датасет на части, оценивая его сложность
        Т.е. учим не только модель, но и саму схему обучения (веса для вопросов)

        Используют размеченные данные, но разметка не для сложности, а для исходной задачи

        Это больше SPL чем CL, т.к. тут учитывается поведение модели во время обучения

    * Датасеты:
        # MCTest-500 dataset (Richardson et al., 2013)
        # 855 third, fourth, fifth grade science questions derived from regional and state science exams (http://aristo-public-data.s3.amazonaws.com/AI2-Elementary-NDMC-Feb2016.zip)
        # Publicly available science textbooks (ck12.org)
        # Simple English Wikipedia
        # For QANTA (Iyyer et al., 2014), we use questions from quiz bowl tournaments for training as in Iyyer et al. (2014).
        # synthetic QA tasks defined in Weston et al. (2015) (version 1.1 of the dataset)

[21:43] Обзор статьи https://www.aclweb.org/anthology/N19-1119.pdf
    * Используют датасет WMT-16
    * Решаеют задачу NMT (Neural Machine Translation)
    * Общая схема проста, а именно давайте обучать модель следующим образом:
        # Введем функцию сложности примеров из датасета (d(x_i))
        # Введем функцию, которая будет показывать, насколько наша модель крута (c(t) - крутость во время t)
        # Дальше будем повторять процесс: рассмотрим все примеры i: d(x_i) <= c(t), равномерно возьмем батч данных из таких примеров, обучим, повторим
    * Функции сложности:
        1) Для данных
            # Длина предложения
            # Частота слова в датасете (кол-во вхождений / сумму длин предложений)
            # Комбинируем => считаем -loglikelyhood, а именно d(s_i) = -\sum_k\log p(w_k^i)
            Ооо. 
                "These are just two examples of difficulty metrics,
                and it is easy to conceive of other metrics such as
                the occurrence of homographs (Liu et al., 2018) or
                context-sensitive words (Bawden et al., 2018), the
                examination of which we leave for future work." - на самом интересном месте кукареки про метрики закончились
        2) Для оценки крутости модели
            "More sophisticated strategies that depend on the
            loss function, the loss gradient, or on the learner’s
            performance on held-out data, are possible, but we
            do not consider them in this paper" - мдааа

            Используют линейную и еще какую-то мудреную (так корневая) функцию, зависящую только от числа итераций...

[14:04]
    Мысли про то, как можно сранивать подходы к оценке сложности и ражнирования:
        Берем два берта, рандомно прроинциализированных
            обучаем с помощью CL, используя первый подход => Bert1
            обучаем с помощью CL, используя второй подход => Bert2
            Дальше дообучаем оба берта на конкретной задаче, смотрим на графики обучения

            Или берем два берта предобученных берта (2 копии), обучаем на downstream тасках по-разному, смотрим на графики

[14:08] Озбор статьи https://www.aclweb.org/anthology/2020.acl-main.542.pdf
    * Применяют CL на стадии fine-tuning'а
    * Работают с BERT'ом
    * Решают NLU таски
    * Они монстры с огромными мощностями:
        Давайте на каждой эпохе учить BERT так:
            # Пусть у нас есть текущий BERT_0
            # Возьмем текущий датасет, поделим равновероятно на N частей
            # Обучим N BERT'ов на этих N частях
            # Дальше для каждого семпла d_i найдем k-ый бин, в котором он находится, посчитаем сумму скоров (F1/accuracy) всех BERT'ов кроме k-го, скажем, что это сложность
            # Дальше посортим все семплы, поделим на N частей
            # Дальше будем N раз делать следующее: на i итерации будем смотреть на 1,...,i бины по сложности и семплить из них примеры с вер-ми, пропорциональными их сложностям
    * Кажется, это вообще не CL, а SPL
    * У них не совсем сложность, т.к. каждый раз они делят датасет на N частей случайным образом, т.е. и сложные, и легки примеры замешиваются постоянно
    * А работает у них, скорее всего, потому что модель просто ест сначала примеры, на которых она более уверена
    * Еще чтобы это сделать, нужны огромные мощности
    * Они это делают для конкретной таски...

[15:41]
    Вариант ранжирования:
    На каждой эпохе равномерно делить на части, сортировать по метрике
